{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils' from 'f:\\\\data science\\\\ml projects\\\\ml project by engineering wala bhaiya\\\\ml_pipeline_project\\\\src\\\\utils.py'>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import src\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from typing import Optional, Union\n",
    "from src.utils import fetch_data\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import TargetEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "importlib.reload(src.utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipelines(model_name: str, model):\n",
    "    with open('config/data_config/transform_features.json', 'r') as json_file:\n",
    "        transform_features = json.load(json_file)\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), transform_features['target_features']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    model_pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('target', preprocessor),\n",
    "            (model_name, model(n_jobs=-1))\n",
    "        ]\n",
    "    )\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(X_train, y_train, model_name: str, model, scores):\n",
    "    model_pipeline = model_pipelines(model_name, model, random_state=42)\n",
    "    model_pipeline.fit(X_train, np.ravel(y_train))\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    model_name: str,\n",
    "    model,\n",
    "    scoring: list,\n",
    "    n_iter: int,\n",
    "    param_distributions: Union[dict, list],\n",
    "    **kwagr):\n",
    "    model_pipeline = model_pipelines(model_name, model, **kwagr)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=8, shuffle=True, random_state=42)\n",
    "    random_best_search = RandomizedSearchCV(\n",
    "        estimator=model_pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        refit='f1',\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    return random_best_search.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Measuring Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_scores(estimator, X_test, y_test):\n",
    "\n",
    "  y_pred = estimator.predict(X_test)\n",
    "\n",
    "  metrics = {\n",
    "      'accuracy': accuracy_score,\n",
    "      'balanced_accuracy': balanced_accuracy_score,\n",
    "      'precision': precision_score,\n",
    "      'recall': recall_score,\n",
    "      'f1': f1_score,\n",
    "      'roc_auc': roc_auc_score\n",
    "  }\n",
    "\n",
    "  for metric_name, metric_func in metrics.items():\n",
    "      if metric_name == 'roc_auc':\n",
    "          score = metric_func(y_test, estimator.predict_proba(X_test)[:, 1])\n",
    "      else:\n",
    "          score = metric_func(y_test, y_pred)\n",
    "      print(f\"{metric_name}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Cross Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cv_scores(\n",
    "    results: dict,\n",
    "    scores: list,\n",
    "    save_json: bool = False,\n",
    "    save_path: Optional[str] = None,\n",
    "    name: Optional[str] = None,\n",
    "    show_test_scores: bool = True,\n",
    "    show_train_scores: bool =  False\n",
    "    )-> dict:\n",
    "    \n",
    "    if save_json and (save_path is None or name is None):\n",
    "        raise ValueError(\"save_path and name must be provided if save_json is True\")\n",
    "    \n",
    "    model_test_scores = []\n",
    "    model_train_scores = []\n",
    "    \n",
    "    for score in scores:\n",
    "        model_test_scores.append(f'mean_test_{score}')\n",
    "        model_test_scores.append(f'std_test_{score}')\n",
    "        \n",
    "    for score in scores:\n",
    "        model_train_scores.append(f'mean_train_{score}')\n",
    "        model_train_scores.append(f'std_train_{score}')\n",
    "    \n",
    "    keys = []\n",
    "    if show_test_scores:\n",
    "        keys.extend(model_test_scores)\n",
    "    if show_train_scores:\n",
    "        keys.extend(model_train_scores)\n",
    "    if not keys:\n",
    "        raise ValueError('You must show either test or train scores')\n",
    "    \n",
    "    cv_scores = {key: np.average(results[key]) for key in keys}\n",
    "    \n",
    "    if save_json:\n",
    "        save_cv_scores = {key: np.average(results[key]) for key in model_test_scores + model_train_scores}\n",
    "        with open(f\"{save_path}/{name}\", 'w') as json_file:\n",
    "            json.dump(save_cv_scores, json_file, indent=4)\n",
    "    \n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(estimator, scores: dict, path: str, basic_name: str):\n",
    "  pr_scores = {key: round(scores[key], 6) for key in scores.keys() if key in ['precision', 'recall']}\n",
    "  model_name = basic_name + f\"_p{pr_scores['precision']}_r{pr_scores['recall']}\"\n",
    "  with open(f\"{path}/{model_name}.pkl\", 'wb') as f:\n",
    "    joblib.dump(estimator, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save Trained Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_pipeline(trained_pipeline, path: str, name: str):\n",
    "  with open(f\"{path}/{name}.pkl\", 'wb') as f:\n",
    "    joblib.dump(trained_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_params(params: dict, scores: dict, path: str, basic_name: str):\n",
    "  pr_scores = {key: round(scores[key], 6) for key in scores.keys() if key in ['precision', 'recall']}\n",
    "  name = basic_name + f\"_p{pr_scores['precision']}_r{pr_scores['recall']}\"\n",
    "  with open(f\"{path}/{name}.json\", 'w') as json_file:\n",
    "    json.dump(params, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_configs(\n",
    "    estimator,\n",
    "    trained_pipeline,\n",
    "    cv_results: dict,\n",
    "    params:dict,\n",
    "    scores: dict,\n",
    "    model_save_path: str,\n",
    "    model_name: str,\n",
    "    pipeline_save_path: str,\n",
    "    pipeline_name: str,\n",
    "    model_params_save_path: str,\n",
    "    model_params_name: str,\n",
    "    cv_scores_save_path: str,\n",
    "    cv_scores_name: str,\n",
    "    ):\n",
    "  save_model(\n",
    "      estimator=estimator,\n",
    "      scores=scores,\n",
    "      path=model_save_path,\n",
    "      basic_name=model_name\n",
    "      )\n",
    "  \n",
    "  save_trained_pipeline(\n",
    "      trained_pipeline=trained_pipeline,\n",
    "      path=pipeline_save_path,\n",
    "      name=pipeline_name\n",
    "      )\n",
    "  \n",
    "  save_model_params(\n",
    "      params=params,\n",
    "      scores=scores,\n",
    "      path=model_params_save_path,\n",
    "      basic_name=model_params_name\n",
    "      )\n",
    "  \n",
    "  cv_scores = model_cv_scores(\n",
    "      results=cv_results,\n",
    "      scores=scores,\n",
    "      save_json=True,\n",
    "      save_path=cv_scores_save_path,\n",
    "      name=cv_scores_name\n",
    "      )\n",
    "  \n",
    "  for key, value in cv_scores.items():\n",
    "    print(key.replace('_', ' ').title(), ':', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data From the Sourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = fetch_data(FILE_NAME='X_train_transformed.csv', DIRECTORY_NAME='featured')\n",
    "X_test_transformed = fetch_data(FILE_NAME='X_test_transformed.csv', DIRECTORY_NAME='featured')\n",
    "X_train_simple_transformed = fetch_data(FILE_NAME='X_train_simple_transformed.csv', DIRECTORY_NAME='processed')\n",
    "X_test_simple_transformed = fetch_data(FILE_NAME='X_test_simple_transformed.csv', DIRECTORY_NAME='processed')\n",
    "y_train = fetch_data(FILE_NAME='y_train_transformed.csv', DIRECTORY_NAME='featured')\n",
    "y_test = fetch_data(FILE_NAME='y_test_transformed.csv', DIRECTORY_NAME='featured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Baseline Random Forest\n",
    "This section will only based on the `base-line models`, where we go through different sets which involved newly extracted `featured set` and only simple `processed set` of income dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Baseline Random Forest on Featured Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_featured = baseline_model(X_train_transformed, y_train, 'random_forest', RandomForestClassifier, scores)\n",
    "model_scores = measure_scores(baseline_model_featured, X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models/random_forest/random_forest_featured_set'\n",
    "save_model(\n",
    "    estimator=baseline_model_featured,\n",
    "    scores=model_scores,\n",
    "    path=model_save_path,\n",
    "    basic_name='random_forest_baseline'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. BaseLine Random Forest on Simple Processed Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_featured = baseline_model(X_train_simple_transformed, y_train, 'random_forest', RandomForestClassifier, scores)\n",
    "model_scores = measure_scores(baseline_model_featured, X_test_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models/random_forest/random_forest_simple_featured_set'\n",
    "save_model(\n",
    "    estimator=baseline_model_featured,\n",
    "    scores=model_scores,\n",
    "    path=model_save_path,\n",
    "    basic_name='random_forest_baseline'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Forest With Hyper Parameter Tuning\n",
    "This section is based on the model with hyper tuned parameters both on the newly `extracted featured set` and simple `transformed featured set` of income dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Tuned Random Forest on Featured Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ***** Do not suppose to run this code onto this system, cause it's been trained on Google Colab *****\n",
    "\n",
    "with open('config/model_config/random_forest_params.json', 'r') as json_file:\n",
    "    random_forest_param_distributions = json.load(json_file)\n",
    "\n",
    "\n",
    "random_search = train_model(\n",
    "    X_train_transformed,\n",
    "    y_train,\n",
    "    'random_forest',\n",
    "    RandomForestClassifier,\n",
    "    scores,\n",
    "    n_iter=30,\n",
    "    params_path=random_forest_param_distributions\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.865711361310133\n",
      "balanced_accuracy: 0.7820435033835814\n",
      "precision: 0.7910447761194029\n",
      "recall: 0.6173044925124792\n",
      "f1: 0.6934579439252336\n",
      "roc_auc: 0.9210946051991363\n"
     ]
    }
   ],
   "source": [
    "with open('models/random_forest/random_forest_featured_set/random_forest_tuned_p0.791045_r0.617304.pkl', 'rb') as estemator:\n",
    "    random_forest_tuned = joblib.load(estemator)\n",
    "\n",
    "model_scores = measure_scores(random_forest_tuned, X_test_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ***** Do not suppose to run this code onto this system, cause it's been trained on Google Colab *****\n",
    "\n",
    "model_save_path = 'models/random_forest/random_forest_featured_set'\n",
    "save_model(\n",
    "    estimator=random_search.best_estimator_,\n",
    "    scores=model_scores,\n",
    "    path=model_save_path,\n",
    "    basic_name='random_forest_tuned'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ***** Do not suppose to run this code onto this system, cause it's been trained on Google Colab *****\n",
    "\n",
    "pipeline_save_path = 'models/random_forest/random_forest_featured_set/random_forest_trained_pipeline'\n",
    "save_trained_pipeline(\n",
    "    trained_pipeline=random_search.best_estimator_,\n",
    "    path=pipeline_save_path,\n",
    "    name='random_forest_trained_pipeline'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ***** Do not suppose to run this code onto this system, cause it's been trained on Google Colab *****\n",
    "\n",
    "model_params_save_path = 'config/model_config'\n",
    "save_model_params(\n",
    "    params=random_search.best_params_,\n",
    "    scores=model_scores,\n",
    "    path=model_params_save_path,\n",
    "    basic_name='random_forest_tuned_params'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ***** Do not suppose to run this code onto this system, cause it's been trained on Google Colab *****\n",
    "\n",
    "cv_scores_save_path = 'models/random_forest/random_forest_featured_set/random_forest_trained_pipeline'\n",
    "cv_scores = model_cv_scores(\n",
    "    results=random_search.cv_results_,\n",
    "    scores=scores,\n",
    "    save_json=True,\n",
    "    save_path=cv_scores_save_path,\n",
    "    name='random_forest_tuned_cv_scores.json',\n",
    "    show_test_scores=True,\n",
    ")\n",
    "\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_accuracy': 0.8603282099390548,\n",
       " 'std_test_accuracy': 0.004069708330945389,\n",
       " 'mean_test_balanced_accuracy': 0.7702609637927857,\n",
       " 'std_test_balanced_accuracy': 0.00858864047247017,\n",
       " 'mean_test_precision': 0.7697937247792505,\n",
       " 'std_test_precision': 0.008452635427149257,\n",
       " 'mean_test_recall': 0.5971331768570057,\n",
       " 'std_test_recall': 0.01811029719303307,\n",
       " 'mean_test_f1': 0.6719312940360602,\n",
       " 'std_test_f1': 0.01272904679431401,\n",
       " 'mean_test_roc_auc': 0.9138426382291606,\n",
       " 'std_test_roc_auc': 0.0049910019846350195}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_save_path = 'models/random_forest/random_forest_featured_set/random_forest_trained_tuned_pipeline'\n",
    "with open(f'{cv_scores_save_path}/random_forest_trained_pipeline.pkl', 'rb') as f:\n",
    "    trained_pipeline = joblib.load(f)\n",
    "model_cv_scores(results=trained_pipeline.cv_results_, scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Random Forest With Hyper Parameter Tuning on Simple Processed Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = 'config/model_config/random_forest_params.json'\n",
    "\n",
    "random_search = train_model(\n",
    "    X_train_simple_transformed,\n",
    "    y_train,\n",
    "    'random_forest',\n",
    "    RandomForestClassifier,\n",
    "    scores,\n",
    "    n_iter=30,\n",
    "    params_path=params_path\n",
    "    )\n",
    "\n",
    "model_scores = measure_scores(random_search.best_estimator_, X_test_simple_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. BaseLine Logistic Regression\n",
    "This section will only based on the `base-line models`, where we go through different sets which involved newly extracted `featured set` and only simple `processed set` of income dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. BaseLine Logistic Regression on Featured Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_featured = baseline_model(X_train_transformed, y_train, 'logistic_regression', LogisticRegression, scores)\n",
    "model_scores = measure_scores(baseline_model_featured, X_test_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models/logistic_regression/logistic_regression_featured_set'\n",
    "save_model(\n",
    "    estimator=baseline_model_featured,\n",
    "    scores=model_scores,\n",
    "    path=model_save_path,\n",
    "    basic_name='logistic_regression_baseline'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. BaseLine Logistic Regression on Simple Processed Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_simple_featured = baseline_model(X_train_simple_transformed, y_train, 'logistic_regression', LogisticRegression, scores)\n",
    "model_scores = measure_scores(baseline_model_simple_featured, X_test_simple_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models/logistic_regression/logistic_regression_simple_featured_set'\n",
    "save_model(\n",
    "    estimator=baseline_model_featured,\n",
    "    scores=model_scores,\n",
    "    path=model_save_path,\n",
    "    basic_name='logistic_regression_baseline'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression With Hyper Parameter Tuning\n",
    "This section is based on the model with hyper tuned parameters both on the newly `extracted featured set` and simple `transformed featured set` of income dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Logistic Regression With Hyper Parameter Tuning on Featured Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'config/model_config/logistic_regression/logistic_regression_params.json'\n",
    "with open(path, 'r') as json_file:\n",
    "    logistic_regression_params = json.load(json_file)\n",
    "\n",
    "random_search = train_model(\n",
    "    X_train_transformed,\n",
    "    y_train,\n",
    "    'logistic_regression',\n",
    "    LogisticRegression,\n",
    "    scores,\n",
    "    n_iter=30,\n",
    "    param_distributions=logistic_regression_params\n",
    "    )\n",
    "\n",
    "model_scores = measure_scores(random_search.best_estimator_, X_test_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_configs(\n",
    "    estimator=random_search.best_estimator_,\n",
    "    trained_pipeline=random_search,\n",
    "    cv_results=random_search.cv_results_,\n",
    "    params=random_search.best_params_,\n",
    "    scores=model_scores,\n",
    "    model_save_path='models/logistic_regression/logistic_regression_featured_set',\n",
    "    model_name='logistic_regression_tuned',\n",
    "    pipeline_save_path='models/logistic_regression/logistic_regression_featured_set/logistic_regression_trained_tuned_pipeline',\n",
    "    pipeline_name='logistic_regression_trained_pipeline',\n",
    "    model_params_save_path='config/model_config/logistic_regression/logistic_regression_featured_set',\n",
    "    model_params_name='logistic_regression_tuned_params',\n",
    "    cv_scores_save_path='models/logistic_regression/logistic_regression_featured_set/logistic_regression_trained_tuned_pipeline',\n",
    "    cv_scores_name='logistic_regression_tuned_cv_scores.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_accuracy': 0.8234658998808505,\n",
       " 'std_test_accuracy': 0.003784368245920948,\n",
       " 'mean_test_balanced_accuracy': 0.7575381298212024,\n",
       " 'std_test_balanced_accuracy': 0.006519037761809717,\n",
       " 'mean_test_precision': 0.6632689686292229,\n",
       " 'std_test_precision': 0.008219455479027577,\n",
       " 'mean_test_recall': 0.6308118783941556,\n",
       " 'std_test_recall': 0.012782841501366953,\n",
       " 'mean_test_f1': 0.6284152180950424,\n",
       " 'std_test_f1': 0.009463117919747244,\n",
       " 'mean_test_roc_auc': 0.8899037261600657,\n",
       " 'std_test_roc_auc': 0.005624433968585372}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_save_path = 'models/logistic_regression/logistic_regression_featured_set/logistic_regression_trained_tuned_pipeline'\n",
    "with open(f'{cv_scores_save_path}/logistic_regression_trained_pipeline.pkl', 'rb') as f:\n",
    "    trained_pipeline = joblib.load(f)\n",
    "model_cv_scores(results=trained_pipeline.cv_results_, scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Logistic Regression With Hyper Parameter Tuning on Simple Processed Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'config/model_config/logistic_regression/logistic_regression_params.json'\n",
    "with open(path, 'r') as json_file:\n",
    "    logistic_regression_params = json.load(json_file)\n",
    "\n",
    "random_search = train_model(\n",
    "    X_train_simple_transformed,\n",
    "    y_train,\n",
    "    'logistic_regression',\n",
    "    LogisticRegression,\n",
    "    scores,\n",
    "    n_iter=150,\n",
    "    param_distributions=logistic_regression_params\n",
    "    )\n",
    "\n",
    "model_scores = measure_scores(random_search.best_estimator_, X_test_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_configs(\n",
    "    estimator=random_search.best_estimator_,\n",
    "    trained_pipeline=random_search,\n",
    "    cv_results=random_search.cv_results_,\n",
    "    params=random_search.best_params_,\n",
    "    scores=model_scores,\n",
    "    model_save_path='models/logistic_regression/logistic_regression_simple_featured_set',\n",
    "    model_name='logistic_regression_tuned',\n",
    "    pipeline_save_path='models/logistic_regression/logistic_regression_simple_featured_set/logistic_regression_trained_tuned_pipeline',\n",
    "    pipeline_name='logistic_regression_trained_pipeline',\n",
    "    model_params_save_path='config/model_config/logistic_regression/logistic_regression_simple_featured_set',\n",
    "    model_params_name='logistic_regression_tuned_params',\n",
    "    cv_scores_save_path='models/logistic_regression/logistic_regression_simple_featured_set/logistic_regression_trained_tuned_pipeline',\n",
    "    cv_scores_name='logistic_regression_tuned_cv_scores.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_accuracy': 0.7995272011078303,\n",
       " 'std_test_accuracy': 0.003984685473589032,\n",
       " 'mean_test_balanced_accuracy': 0.7458942876148469,\n",
       " 'std_test_balanced_accuracy': 0.006630134347271698,\n",
       " 'mean_test_precision': 0.6158721672186557,\n",
       " 'std_test_precision': 0.009344181518383178,\n",
       " 'mean_test_recall': 0.6428008257396293,\n",
       " 'std_test_recall': 0.013172787657419919,\n",
       " 'mean_test_f1': 0.5902569457535388,\n",
       " 'std_test_f1': 0.010061212180905391,\n",
       " 'mean_test_roc_auc': 0.8703279085617353,\n",
       " 'std_test_roc_auc': 0.006149963878709868}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_save_path = 'models/logistic_regression/logistic_regression_simple_featured_set/logistic_regression_trained_tuned_pipeline'\n",
    "with open(f'{cv_scores_save_path}/logistic_regression_trained_pipeline.pkl', 'rb') as f:\n",
    "    trained_pipeline = joblib.load(f)\n",
    "model_cv_scores(results=trained_pipeline.cv_results_, scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. BaseLine XGBoost Classifier\n",
    "This section will only based on the `base-line models`, where we go through different sets which involved newly extracted `featured set` and only simple `processed set` of income dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. BaseLine XGBoost on Featured Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_featured = baseline_model(X_train_transformed, y_train, 'logistic_regression', xgb.XGBClassifier, scores)\n",
    "model_scores = measure_scores(baseline_model_featured, X_test_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models/XGBoost/XGBoost_featured_set'\n",
    "save_model(\n",
    "    estimator=baseline_model_featured,\n",
    "    scores=model_scores,\n",
    "    path=os.path.join(BASE_PATH, model_save_path),\n",
    "    basic_name='xgboost_baseline'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. BaseLine XGBoost on Simple Featured Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_featured = baseline_model(X_train_simple_transformed, y_train, 'logistic_regression', xgb.XGBClassifier, scores)\n",
    "model_scores = measure_scores(baseline_model_featured, X_test_simple_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models/XGBoost/XGBoost_simple_featured_set'\n",
    "save_model(\n",
    "    estimator=baseline_model_featured,\n",
    "    scores=model_scores,\n",
    "    path=model_save_path,\n",
    "    basic_name='xgboost_baseline'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. XGBoost With Hyper Parameter Tuning\n",
    "This section is based on the model with hyper tuned parameters both on the newly `extracted featured set` and simple `transformed featured set` of income dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. XGBoost With Hyper Parameter Tuning on Featured Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'config/model_config/XGBoost/XGBoost_params.json'\n",
    "with open(path, 'r') as json_file:\n",
    "    xgboost_params = json.load(json_file)\n",
    "\n",
    "random_search = train_model(\n",
    "    X_train_transformed,\n",
    "    y_train,\n",
    "    'xgboost_classifier',\n",
    "    xgb.XGBClassifier,\n",
    "    scores,\n",
    "    n_iter=150,\n",
    "    param_distributions=xgboost_params\n",
    "    )\n",
    "\n",
    "model_scores = measure_scores(random_search.best_estimator_, X_test_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_configs(\n",
    "    estimator=random_search.best_estimator_,\n",
    "    trained_pipeline=random_search,\n",
    "    cv_results=random_search.cv_results_,\n",
    "    params=random_search.best_params_,\n",
    "    scores=model_scores,\n",
    "    model_save_path='models/XGBoost/XGBoost_featured_set',\n",
    "    model_name='XGBoost_tuned',\n",
    "    pipeline_save_path='models/XGBoost/XGBoost_featured_set/XGBoost_trained_tuned_pipeline',\n",
    "    pipeline_name='XGBoost_trained_pipeline',\n",
    "    model_params_save_path='config/model_config/XGBoost/XGBoost_featured_set',\n",
    "    model_params_name='XGBoost_tuned_params',\n",
    "    cv_scores_save_path='models/XGBoost/XGBoost_featured_set/XGBoost_trained_tuned_pipeline',\n",
    "    cv_scores_name='XGBoost_tuned_cv_scores.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_accuracy': 0.8531047392632997,\n",
       " 'std_test_accuracy': 0.005004477909378103,\n",
       " 'mean_test_balanced_accuracy': 0.8138960687666335,\n",
       " 'std_test_balanced_accuracy': 0.008925963185869674,\n",
       " 'mean_test_precision': 0.6825378501441262,\n",
       " 'std_test_precision': 0.009547344314113942,\n",
       " 'mean_test_recall': 0.7385285557186527,\n",
       " 'std_test_recall': 0.018093754620372018,\n",
       " 'mean_test_f1': 0.7057704611565705,\n",
       " 'std_test_f1': 0.011623533264370212,\n",
       " 'mean_test_roc_auc': 0.9187415608657994,\n",
       " 'std_test_roc_auc': 0.005771131165763514}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_save_path = 'models/XGBoost/XGBoost_featured_set/XGBoost_trained_tuned_pipeline'\n",
    "with open(f'{cv_scores_save_path}/XGBoost_trained_pipeline.pkl', 'rb') as f:\n",
    "    trained_pipeline = joblib.load(f)\n",
    "model_cv_scores(results=trained_pipeline.cv_results_, scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. XGBoost With Hyper Parameter Tuning on Simple Featured Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'config/model_config/XGBoost/XGBoost_params.json'\n",
    "with open(path, 'r') as json_file:\n",
    "    xgboost_params = json.load(json_file)\n",
    "\n",
    "random_search = train_model(\n",
    "    X_train_simple_transformed,\n",
    "    y_train,\n",
    "    'xgboost_classifier',\n",
    "    xgb.XGBClassifier,\n",
    "    scores,\n",
    "    n_iter=150,\n",
    "    param_distributions=xgboost_params\n",
    "    )\n",
    "\n",
    "model_scores = measure_scores(random_search.best_estimator_, X_test_transformed, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_configs(\n",
    "    estimator=random_search.best_estimator_,\n",
    "    trained_pipeline=random_search,\n",
    "    cv_results=random_search.cv_results_,\n",
    "    params=random_search.best_params_,\n",
    "    scores=model_scores,\n",
    "    model_save_path='models/XGBoost/XGBoost_simple_featured_set',\n",
    "    model_name='XGBoost_tuned',\n",
    "    pipeline_save_path='models/XGBoost/XGBoost_simple_featured_set/XGBoost_trained_tuned_pipeline',\n",
    "    pipeline_name='XGBoost_trained_pipeline',\n",
    "    model_params_save_path='config/model_config/XGBoost/XGBoost_simple_featured_set',\n",
    "    model_params_name='XGBoost_tuned_params',\n",
    "    cv_scores_save_path='models/XGBoost/XGBoost_simple_featured_set/XGBoost_trained_tuned_pipeline',\n",
    "    cv_scores_name='XGBoost_tuned_cv_scores.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_accuracy': 0.8536053089703163,\n",
       " 'std_test_accuracy': 0.0052195414127829826,\n",
       " 'mean_test_balanced_accuracy': 0.8173201620281749,\n",
       " 'std_test_balanced_accuracy': 0.008946568047939214,\n",
       " 'mean_test_precision': 0.680354148659299,\n",
       " 'std_test_precision': 0.009617007067388925,\n",
       " 'mean_test_recall': 0.7475721898450255,\n",
       " 'std_test_recall': 0.017590401174884657,\n",
       " 'mean_test_f1': 0.7094018599485755,\n",
       " 'std_test_f1': 0.011668951498662742,\n",
       " 'mean_test_roc_auc': 0.9201910891661487,\n",
       " 'std_test_roc_auc': 0.005782584846172538}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_save_path = 'models/XGBoost/XGBoost_simple_featured_set/XGBoost_trained_tuned_pipeline'\n",
    "with open(f'{cv_scores_save_path}/XGBoost_trained_pipeline.pkl', 'rb') as f:\n",
    "    trained_pipeline = joblib.load(f)\n",
    "model_cv_scores(results=trained_pipeline.cv_results_, scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depreciated Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is to making json file for parameter grid of the random forest model.\n",
    "'''\n",
    "random_forest_param_grid = {\n",
    "    'n_estimators' : [100, 200, 300, 400, 500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "with open('config/model_config/random_forest_params.json', 'w') as json_file:\n",
    "    json_file.write(json.dumps(random_forest_param_grid, indent=4))\n",
    "'''\n",
    "\n",
    "'''\n",
    "# os.chdir(os.path.dirname(os.getcwd()))\n",
    "with open('config/data_config/transform_features.json', 'r') as json_file:\n",
    "    transform_features = json.load(json_file)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), transform_features['target_features']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('target', preprocessor),\n",
    "        ('random_forest', RandomForestClassifier(verbose=1, n_jobs=-1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# model_pipeline.named_steps['target'].fit_transform(X_train, y_train)[0, :].shape\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=9, shuffle=True, random_state=42)\n",
    "# scores = cross_validate(model_pipeline, X=X_train, y=y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=8, shuffle=True, random_state=42)\n",
    "grid_search = RandomizedSearchCV(\n",
    "    estimator=model_pipeline,\n",
    "    param_distributions=random_forest_params_grid,\n",
    "    n_iter=20,\n",
    "    scoring=scoring,\n",
    "    cv=cv,\n",
    "    refit='roc_auc',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "grid_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best ROC AUC Score:\", grid_search.best_score_)\n",
    "cv_results = grid_search.cv_results_\n",
    "print(cv_results)\n",
    "\n",
    "# Get the best estimator\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'balanced_accuracy': balanced_accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'f1': f1_score,\n",
    "    'roc_auc': roc_auc_score\n",
    "}\n",
    "\n",
    "for metric_name, metric_func in metrics.items():\n",
    "    if metric_name == 'roc_auc':\n",
    "        score = metric_func(y_test, best_estimator.predict_proba(X_test)[:, 1])\n",
    "    else:\n",
    "        score = metric_func(y_test, y_pred)\n",
    "    print(f\"{metric_name}: {score}\")\n",
    "\n",
    "for key in list(scores.keys())[2:]:\n",
    "    print(f\"Average {key.replace('_', ' ').title()}: {scores[key].mean()}\")\n",
    "'''\n",
    "\n",
    "# This code is use to make the parameter distribution of logistic regression\n",
    "'''\n",
    "logistic_regression_params_dist = {\n",
    "    'logistic_regression__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'logistic_regression__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'logistic_regression__solver': ['liblinear', 'lbfgs', 'saga'],\n",
    "    'logistic_regression__max_iter': [100, 200, 500],\n",
    "    'logistic_regression__class_weight': [None, 'balanced', {0: 1, 1: 2}],\n",
    "    'logistic_regression__tol': [1e-4, 1e-3, 1e-2],\n",
    "    'logistic_regression__multi_class': ['ovr'],\n",
    "    'logistic_regression__l1_ratio':{\n",
    "        \"elasticnet\": [0.1, 0.5, 0.9]  # Only used if penalty='elasticnet'\n",
    "    }\n",
    "}\n",
    "\n",
    "path = 'config/model_config/logistic_regression/logistic_regression_params_distribution.json'\n",
    "with open(os.path.join(BASE_PATH, path), 'w') as json_file:\n",
    "    json.dump(logistic_regression_params_dist, json_file, indent=4)\n",
    "\n",
    "logistic_regression_param_grid = []\n",
    "for penalty, solver in zip(\n",
    "    logistic_regression_params_dist[\"logistic_regression__penalty\"],\n",
    "    logistic_regression_params_dist[\"logistic_regression__solver\"]):\n",
    "    params = {\n",
    "        # \"logistic_regression__penalty\": [penalty],\n",
    "        \"logistic_regression__C\": logistic_regression_params_dist[\"logistic_regression__C\"],\n",
    "        # \"logistic_regression__solver\": logistic_regression_params_dist[\"logistic_regression__solver\"],\n",
    "        \"logistic_regression__max_iter\": logistic_regression_params_dist[\"logistic_regression__max_iter\"],\n",
    "        \"logistic_regression__class_weight\": logistic_regression_params_dist[\"logistic_regression__class_weight\"][:-1],\n",
    "        \"logistic_regression__tol\": logistic_regression_params_dist[\"logistic_regression__tol\"],\n",
    "        \"logistic_regression__multi_class\": logistic_regression_params_dist[\"logistic_regression__multi_class\"]\n",
    "    }\n",
    "\n",
    "    if penalty == \"elasticnet\":\n",
    "        params[\"logistic_regression__l1_ratio\"] = logistic_regression_params_dist[\"logistic_regression__l1_ratio\"][\"elasticnet\"]\n",
    "    \n",
    "    if solver == 'lbfgs':\n",
    "        params['logistic_regression__penalty'] = ['l2']\n",
    "        params['logistic_regression__solver'] = ['lbfgs']\n",
    "    elif solver == 'liblinear':\n",
    "        params['logistic_regression__penalty'] = ['l1', 'l2']\n",
    "        params['logistic_regression__solver'] = ['liblinear']\n",
    "    elif solver == 'saga':\n",
    "        params['logistic_regression__penalty'] = ['elasticnet', 'l1', 'l2']\n",
    "        params['logistic_regression__solver'] = ['saga']\n",
    "    \n",
    "    logistic_regression_param_grid.append(params)\n",
    "logistic_regression_param_grid\n",
    "\n",
    "path = 'config/model_config/logistic_regression/logistic_regression_params.json'\n",
    "with open(os.path.join(BASE_PATH, path), 'w') as json_file:\n",
    "    json.dump(logistic_regression_param_grid, json_file, indent=4)\n",
    "'''\n",
    "\n",
    "# This code is used to defined a hyperparameters on XGBoost for classification problem and then save them into json file\n",
    "'''\n",
    "xgboost_params_grid = {\n",
    "    'xgboost_classifier__objective': ['binary:logistic'],\n",
    "    'xgboost_classifier__max_depth': [3, 6, 9],\n",
    "    'xgboost_classifier__learning_rate': [0.01, 0.1, 0.3],\n",
    "    'xgboost_classifier__n_estimators': [100, 200, 500],\n",
    "    'xgboost_classifier__subsample': [0.8, 1.0],\n",
    "    'xgboost_classifier__colsample_bytree': [0.8, 1.0],\n",
    "    'xgboost_classifier__reg_alpha': [0, 0.1, 1.0],\n",
    "    'xgboost_classifier__reg_lambda': [0, 0.1, 1.0],\n",
    "    'xgboost_classifier__scale_pos_weight': [1.5, 1.86, 2.0, 2.5],\n",
    "    'xgboost_classifier__eval_metric': ['logloss']\n",
    "}\n",
    "path = 'config/model_config/XGBoost/XGBoost_params.json'\n",
    "with open(os.path.join(BASE_PATH, path), 'w') as json_file:\n",
    "    json.dump(xgboost_params_grid, json_file, indent=4)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
