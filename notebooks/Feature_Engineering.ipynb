{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils' from 'f:\\\\data science\\\\ml projects\\\\ml project by engineering wala bhaiya\\\\ml_pipeline_project\\\\src\\\\utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src\n",
    "import importlib\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from src.component.transformation import FrequencyEncoder, Winsorizer\n",
    "from src.component.feature_extraction import FeatureExtractor\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from src.utils import fetch_data, transforme_DataFrame, plot_categorical_features\n",
    "importlib.reload(src.component.feature_extraction)\n",
    "importlib.reload(src.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education_num  capital_gain  capital_loss  hours_per_week   \n",
       "0   39   77516             13          2174             0              40  \\\n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "          workclass  education      marital_status         occupation   \n",
       "0         State-gov  Bachelors       Never-married       Adm-clerical  \\\n",
       "1  Self-emp-not-inc  Bachelors  Married-civ-spouse    Exec-managerial   \n",
       "2           Private    HS-grad            Divorced  Handlers-cleaners   \n",
       "3           Private       11th  Married-civ-spouse  Handlers-cleaners   \n",
       "4           Private  Bachelors  Married-civ-spouse     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex native_country income  \n",
       "0  Not-in-family  White    Male  United-States  <=50K  \n",
       "1        Husband  White    Male  United-States  <=50K  \n",
       "2  Not-in-family  White    Male  United-States  <=50K  \n",
       "3        Husband  Black    Male  United-States  <=50K  \n",
       "4           Wife  Black  Female           Cuba  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data = fetch_data(FILE_NAME=\"Imputed_Income_Dataset_RF.csv\", DIRECTORY_NAME=\"processed\")\n",
    "income_data.columns = [col.replace('-', '_'). strip() for col in income_data.columns]\n",
    "income_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/mappings.json', 'r') as json_file:\n",
    "    mappings = json.load(json_file)\n",
    "with open('config/transform_parameters.json', 'r') as json_file:\n",
    "    transform_parameters = json.load(json_file)\n",
    "with open('config/transform_features.json', 'r') as json_file:\n",
    "    transform_features = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 25 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   age                          32561 non-null  int64  \n",
      " 1   fnlwgt                       32561 non-null  int64  \n",
      " 2   education_num                32561 non-null  int64  \n",
      " 3   capital_gain                 32561 non-null  int64  \n",
      " 4   capital_loss                 32561 non-null  int64  \n",
      " 5   hours_per_week               32561 non-null  int64  \n",
      " 6   workclass                    32561 non-null  object \n",
      " 7   education                    32561 non-null  object \n",
      " 8   marital_status               32561 non-null  object \n",
      " 9   occupation                   32561 non-null  object \n",
      " 10  relationship                 32561 non-null  object \n",
      " 11  race                         32561 non-null  object \n",
      " 12  sex                          32561 non-null  object \n",
      " 13  native_country               32561 non-null  object \n",
      " 14  income                       32561 non-null  object \n",
      " 15  age_group                    32561 non-null  object \n",
      " 16  employment_type              32561 non-null  object \n",
      " 17  work_life_balance            32561 non-null  float64\n",
      " 18  over_time_flag               32561 non-null  int32  \n",
      " 19  net_capital                  32561 non-null  int64  \n",
      " 20  education_level_group        32561 non-null  object \n",
      " 21  is_educated_flag             32561 non-null  int64  \n",
      " 22  year_of_education_remaining  32561 non-null  int64  \n",
      " 23  is_married_flag              32561 non-null  int32  \n",
      " 24  region                       32561 non-null  object \n",
      "dtypes: float64(1), int32(2), int64(9), object(13)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "extract = FeatureExtractor()\n",
    "income_data = extract.fit_transform(income_data)\n",
    "income_data['age_group'] = income_data['age_group'].astype('object')\n",
    "income_data['employment_type'] = income_data['employment_type'].astype('object')\n",
    "income_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    income_data.drop(columns=['income']),\n",
    "    income_data['income'],\n",
    "    test_size=0.15,\n",
    "    random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Encode X Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping those columns that are not suppose to encode.\n",
    "X_train_droped = X_train.drop(columns=transform_features['target_features'])\n",
    "X_test_droped = X_test.drop(columns=transform_features['target_features'])\n",
    "\n",
    "# Applying Column Transformer to the whole dataset excetp on target features.\n",
    "X_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(drop='first'), transform_features['onehot_features']),\n",
    "        ('ordinal', OrdinalEncoder(\n",
    "            categories=list(transform_parameters.values())[:-1]\n",
    "            ), transform_features['ordinal_features']),\n",
    "        ('frequency', FrequencyEncoder(), transform_features['frequency_features']),\n",
    "        ('winsorizer', Winsorizer(\n",
    "            feature_limits=transform_parameters['winsorize_limit']\n",
    "            ), transform_features['winsorize_featues']),\n",
    "        ('minmax', MinMaxScaler(), transform_features['scale_features']),\n",
    "        ('remainders', 'passthrough', transform_features['remander_features']),\n",
    "        # We will use target encoder duting the training and validation process.\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fitting, Nameing & Transforming features on X_train_droped and X_test_droped.\n",
    "X_preprocessor.fit(X=X_train_droped, y=y_train)\n",
    "for name, cols in zip(\n",
    "    ['frequency', 'winsorizer'],\n",
    "    [transform_features['frequency_features'], transform_features['winsorize_featues']]\n",
    "    ):\n",
    "    X_preprocessor.named_transformers_[name].set_feature_names(cols)\n",
    "X_train_transformed = X_preprocessor.transform(X_train_droped)\n",
    "X_test_transformed = X_preprocessor.transform(X_test_droped)\n",
    "\n",
    "# Converting them back into dataframes based on there columns name.\n",
    "X_train_transformed = transforme_DataFrame(transformed=X_train_transformed, preprocessor=X_preprocessor)\n",
    "X_test_transformed = transforme_DataFrame(transformed=X_test_transformed, preprocessor=X_preprocessor)\n",
    "\n",
    "# Dropping duplicated columns by choosing scaled versioned of them.\n",
    "duplicated_features = transform_features['winsorize_featues']\n",
    "scale_X_train = X_train_transformed[duplicated_features]\n",
    "scale_X_test = X_test_transformed[duplicated_features]\n",
    "scale_X_train = scale_X_train.loc[:, (scale_X_train.ge(0) & scale_X_train.le(1)).all()]\n",
    "scale_X_test = scale_X_test.loc[:, (scale_X_test.ge(0) & scale_X_test.le(1)).all()]\n",
    "\n",
    "# Dropping all the duplicated columns that share intersection by name.\n",
    "X_train_transformed.drop(columns=duplicated_features, axis=1, inplace=True)\n",
    "\n",
    "# Adding the target features (dropped ones) and scaled features back into the dataframes.\n",
    "X_train_transformed = pd.concat(\n",
    "    [\n",
    "        scale_X_train,\n",
    "        X_train[transform_features['target_features']].reset_index(drop=True),\n",
    "        X_train_transformed\n",
    "        ],\n",
    "    axis=1\n",
    "    )\n",
    "X_test_transformed = pd.concat(\n",
    "    [\n",
    "        scale_X_test,\n",
    "        X_test[transform_features['target_features']].reset_index(drop=True),\n",
    "        X_test_transformed\n",
    "        ],\n",
    "    axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Encode Y Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make object for the label encoder and converting them back into Pandas Series for X_train and X_test.\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_transformed = transforme_DataFrame(\n",
    "    label_encoder.fit_transform(y_train),\n",
    "    label_encoder,\n",
    "    matrix=False\n",
    "    )\n",
    "y_train_transformed.name = y_train.name\n",
    "\n",
    "y_test_transformed = transforme_DataFrame(\n",
    "    label_encoder.transform(y_test),\n",
    "    label_encoder,\n",
    "    matrix=False\n",
    "    )\n",
    "y_test_transformed.name = y_train.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Save All Set's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data.to_csv('data/featured/income_data.csv', index=False)\n",
    "X_train_transformed.to_csv('data/featured/X_train_transformed.csv', index=False)\n",
    "X_test_transformed.to_csv('data/featured/X_test_transformed.csv', index=False)\n",
    "y_train_transformed.to_csv('data/featured/y_train_transformed.csv', index=False)\n",
    "y_test_transformed.to_csv('data/featured/y_test_transformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depreciated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check is there is no outlier in higher capital gain -> So, found nothing\n",
    "'''income_data.loc[income_data['capital_gain'].nlargest(n=30).index]'''\n",
    "\n",
    "# Mapping country_to_region & education_mapping in to JSON File.\n",
    "'''country_to_region = {\n",
    "    'United-States': 'North America',\n",
    "    'Cuba': 'Caribbean',\n",
    "    'Jamaica': 'Caribbean',\n",
    "    'India': 'Asia',\n",
    "    'Mexico': 'North America',\n",
    "    'South': 'Asia',\n",
    "    'Puerto-Rico': 'Caribbean',\n",
    "    'Honduras': 'Central America',\n",
    "    'England': 'Europe',\n",
    "    'Canada': 'North America',\n",
    "    'Germany': 'Europe',\n",
    "    'Iran': 'Asia',\n",
    "    'Philippines': 'Asia',\n",
    "    'Poland': 'Europe',\n",
    "    'Columbia': 'South America',\n",
    "    'Cambodia': 'Asia',\n",
    "    'Thailand': 'Asia',\n",
    "    'Ecuador': 'South America',\n",
    "    'Laos': 'Asia',\n",
    "    'Taiwan': 'Asia',\n",
    "    'Haiti': 'Caribbean',\n",
    "    'Portugal': 'Europe',\n",
    "    'Dominican-Republic': 'Caribbean',\n",
    "    'El-Salvador': 'Central America',\n",
    "    'France': 'Europe',\n",
    "    'Guatemala': 'Central America',\n",
    "    'Italy': 'Europe',\n",
    "    'China': 'Asia',\n",
    "    'Japan': 'Asia',\n",
    "    'Yugoslavia': 'Europe',\n",
    "    'Peru': 'South America',\n",
    "    'Outlying-US(Guam-USVI-etc)': 'Oceania',\n",
    "    'Scotland': 'Europe',\n",
    "    'Trinadad&Tobago': 'Caribbean',\n",
    "    'Greece': 'Europe',\n",
    "    'Nicaragua': 'Central America',\n",
    "    'Vietnam': 'Asia',\n",
    "    'Hong': 'Asia',\n",
    "    'Ireland': 'Europe',\n",
    "    'Hungary': 'Europe',\n",
    "    'Holand-Netherlands': 'Europe'\n",
    "}\n",
    "\n",
    "education_map = {\n",
    "    'Preschool': 'Low',\n",
    "    '1st-4th': 'Low',\n",
    "    '5th-6th': 'Low',\n",
    "    '7th-8th': 'Medium',\n",
    "    '9th': 'Medium',\n",
    "    '10th': 'Medium',\n",
    "    '11th': 'Medium',\n",
    "    '12th': 'Medium',\n",
    "    'HS-grad': 'Medium',\n",
    "    'Some-college': 'High',\n",
    "    'Assoc-voc': 'High',\n",
    "    'Assoc-acdm': 'High',\n",
    "    'Bachelors': 'High',\n",
    "    'Masters': 'High',\n",
    "    'Doctorate': 'High',\n",
    "    'Prof-school': 'High'\n",
    "}\n",
    "\n",
    "combined_mappings = {\n",
    "    'education_map': education_map,\n",
    "    'continent_map': country_to_region\n",
    "}\n",
    "\n",
    "combined_mappings_json = json.dumps(obj=combined_mappings, indent=4)\n",
    "\n",
    "with open('config/mappings.json', 'w') as json_file:\n",
    "    json_file.write(combined_mappings_json)'''\n",
    "\n",
    "# Feature Extraction    \n",
    "'''\n",
    "# 1. Extract Age Groups from -> Age\n",
    "income_data['age_group'] = pd.cut(x=income_data['age'], bins=[0, 18, 35, 55, income_data['age'].max() + 20], labels=['Childern', 'Young Adults', 'Middle Aged', 'Seniors']).astype('object')\n",
    "\n",
    "# 2. Obtain Employment Type from -> Hours Per Week\n",
    "income_data['employment_type'] = pd.cut(x=income_data['hours_per_week'], bins=[0, 20, 40, income_data['hours_per_week'].max() + 1], labels=['Part-Time', 'Full-Time', 'Over-Time']).astype('object')\n",
    "\n",
    "# 3. Get Work-Life Balance from -> Hours Per Week and\n",
    "income_data['work_life_balance'] = income_data['hours_per_week']/168\n",
    "\n",
    "# 4. Fetch Over Time Flag from -> Employment Type\n",
    "income_data['over_time_flag'] = np.where(income_data['employment_type'] == 'Over-Time', 1, 0)  # this is also by using .apply()\n",
    "\n",
    "# 5. Secure Net Capital from -> Capilat Gain & Capilat Loss\n",
    "income_data['net_capital'] = income_data['capital_gain'] - income_data['capital_loss']\n",
    "\n",
    "# 6. Gather Education Level Group from -> Education\n",
    "education_map = mappings['education_map']\n",
    "income_data['education_level_group'] = income_data['education'].map(education_map)\n",
    "\n",
    "# 7. Collect Is Educated Flage from -> Education Number\n",
    "income_data['is_educated_flag'] = income_data['education_num'].apply(lambda x: 1 if x >10 else 0)  # Educated if Education Level > 10 (Threshold)\n",
    "\n",
    "# 8. Coin Year of Education Remaining from -> Education Number\n",
    "income_data['year_of_education_remaining'] = income_data['education_num'].max() - income_data['education_num']\n",
    "\n",
    "# 9. Attain Is Married Flage from -> Marital Status\n",
    "is_married = income_data['marital_status'].str.contains(r'\\bMarried\\b', regex=True)\n",
    "income_data['is_married_flag'] = np.where(is_married, 1, 0)\n",
    "\n",
    "# 10. Extract Region from -> Native Country\n",
    "country_to_region = mappings['country_to_region_mapping']\n",
    "income_data['region'] = income_data['native_country'].map(country_to_region)\n",
    "'''\n",
    "\n",
    "# For Checking the Skewness\n",
    "'''\n",
    "for col in income_data_int.drop(columns='income').columns:\n",
    "    if income_data_int[col].skew() > 1:\n",
    "        print(f'Skewness of {col} is : {income_data_int[col].skew()}')\n",
    "\n",
    "income_data_int = income_data.select_dtypes(exclude=['object'])\n",
    "income_data_int = pd.concat([income_data_int, income_data['income']], axis=1)\n",
    "\n",
    "plot_categorical_features(\n",
    "    data=income_data_int,\n",
    "    columns=income_data_int.drop(columns='income').columns,\n",
    "    fixed_hue='income',\n",
    "    plot_type='histplot',\n",
    "    y_axis_label='Income',\n",
    "    subplot_title=[f'{feature} vs income' for feature in income_data_int.columns.to_list()],\n",
    "    main_title=\"features vs income distribution\",\n",
    "    palette='Set1',\n",
    "    kde=True\n",
    ")\n",
    "'''\n",
    "\n",
    "# This code is for grouping features under respective encoder & makeing it into JSON File.\n",
    "'''\n",
    "transform_features = {\n",
    "    'onehot_features' : ['sex', 'race', 'region', 'employment_type'],\n",
    "    'ordinal_features' : ['education', 'age', 'education_level_group', 'age_group'],\n",
    "    'frequency_features' : ['workclass', 'occupation', 'native_country'],\n",
    "    'target_features' : ['relationship', 'marital_status'],\n",
    "    'winsorize_featues' : ['hours_per_week', 'capital_gain', 'capital_loss'],\n",
    "    'label_features' : ['income'],\n",
    "}\n",
    "transform_features['remander_features'] = income_data.drop(\n",
    "    columns=[\n",
    "        item\n",
    "        for items in list(\n",
    "            transform_features.values()\n",
    "            )\n",
    "        for item in items]\n",
    "    ).columns.tolist()\n",
    "    \n",
    "transform_features_json = json.dumps(transform_features, indent=4)\n",
    "with open('config/transform_features.json', 'w') as json_file:\n",
    "    json_file.write(transform_features_json)\n",
    "'''\n",
    "\n",
    "# This code is for making a dictionary of different features that contain info about the encoder\n",
    "'''\n",
    "limits = [(0.001, 0.988), (0.05, 0.993), (0.00, 0.993)]\n",
    "feature_limits = {feature: limit for feature, limit in zip(transform_features['winsorize_featues'], limits)}\n",
    "\n",
    "transform_parameters = {\n",
    "    'education' : [\n",
    "    'Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th',\n",
    "    'HS-grad', 'Some-college', 'Assoc-acdm', 'Assoc-voc', 'Bachelors', 'Masters',\n",
    "    'Prof-school', 'Doctorate'\n",
    "    ],\n",
    "    \n",
    "    'education_level' : ['Low', 'Medium', 'High'],\n",
    "    \n",
    "    'age_group' : ['Childern', 'Young Adults', 'Middle Aged', 'Seniors'],\n",
    "    \n",
    "    'winsorize_limit' : feature_limits\n",
    "}\n",
    "\n",
    "with open('config/transform_parameters.json', 'w') as json_file:\n",
    "    json_file.write(json.dumps(transform_parameters, indent=4))\n",
    "'''\n",
    "\n",
    "# Making some changes to JSON file for adding scaling features and removing some features form remander_features\n",
    "'''\n",
    "scale_features = []\n",
    "for col in X_train_transformed.iloc[:, 2:].columns:\n",
    "    if (X_train_transformed[col] > 1).any():\n",
    "        scale_features.append(col)\n",
    "scale_features\n",
    "scale_features = [col for col in scale_features if col not in transform_features['ordinal_features']]\n",
    "transform_features['scale_features'] = scale_features\n",
    "[col for col in transform_features['remander_features'] if col in transform_features['scale_features']]\n",
    "with open('config/transform_features.json', 'w') as json_file:\n",
    "    json_file.write(json.dumps(transform_features, indent=4))  # indent=4 for pretty\n",
    "'''\n",
    "\n",
    "# Instead of droping columns we can go through by usin sklearn pipelines\n",
    "'''\n",
    "winsorize_and_scale_features  = list(\n",
    "    set(transform_features['winsorize_featues']) & set(transform_features['scale_features'])\n",
    "    )\n",
    "\n",
    "only_scale_features  = list(\n",
    "    set(transform_features['scale_features']) - set(transform_features['winsorize_featues'])\n",
    "    )\n",
    "\n",
    "temp = Pipeline(steps=[\n",
    "    ('winsorizer', Winsorizer(feature_limits=transform_parameters['winsorize_limit'])),\n",
    "    ('minmax', MinMaxScaler())\n",
    "])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
